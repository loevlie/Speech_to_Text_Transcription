{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "h6Gi1R4nnfxG"
   },
   "source": [
    "# HW4 P2 IDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "id": "OZXkCkQAN4GN"
   },
   "source": [
    "## Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.5.10)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle) (2.22.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: python-slugify in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle) (4.0.1)\n",
      "Requirement already satisfied: six>=1.10 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: urllib3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle) (1.25.10)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle) (4.42.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-slugify->kaggle) (1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "id": "7LPn3mLOoeAe"
   },
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "id": "dyJfQUjIoirw"
   },
   "outputs": [],
   "source": [
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "id": "tbOy2oswo3PX"
   },
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39744,
     "status": "ok",
     "timestamp": 1605194565765,
     "user": {
      "displayName": "Denny Loevlie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giscmna1mRfYQrs9gouTR_IIRLYYZJEaX5ksIjcsg=s64",
      "userId": "17735946205138225469"
     },
     "user_tz": 300
    },
    "id": "B7rUpvASo8wo",
    "outputId": "3bbb0106-343c-468a-e7d1-58a37e7f4aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 11-785-fall-20-homework-4-part-2.zip to /home/ubuntu/AWS_HW4_P2\n",
      "100%|█████████████████████████████████████▉| 3.72G/3.72G [00:59<00:00, 34.5MB/s]\n",
      "100%|██████████████████████████████████████| 3.72G/3.72G [00:59<00:00, 67.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c 11-785-fall-20-homework-4-part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  11-785-fall-20-homework-4-part-2.zip\n",
      "  inflating: hw4p2/dev.npy           \n",
      "  inflating: hw4p2/dev_transcripts.npy  \n",
      "  inflating: hw4p2/sample.csv        \n",
      "  inflating: hw4p2/test.npy          \n",
      "  inflating: hw4p2/train.npy         \n",
      "  inflating: hw4p2/train_transcripts.npy  \n"
     ]
    }
   ],
   "source": [
    "!unzip 11-785-fall-20-homework-4-part-2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "kyznzSkUQHz1"
   },
   "source": [
    "## Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "id": "dBGmKhnNfucr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision   \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset \n",
    "\n",
    "\n",
    "'''\n",
    "Loading all the numpy files containing the utterance information and text information\n",
    "'''\n",
    "def load_data():\n",
    "    speech_train = np.load('./hw4p2/train.npy', allow_pickle=True, encoding='bytes')\n",
    "    speech_valid = np.load('./hw4p2/dev.npy', allow_pickle=True, encoding='bytes')\n",
    "    speech_test = np.load('./hw4p2/test.npy', allow_pickle=True, encoding='bytes')\n",
    "\n",
    "    transcript_train = np.load('./hw4p2/train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "    transcript_valid = np.load('./hw4p2/dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "\n",
    "    return speech_train, speech_valid, speech_test, transcript_train, transcript_valid\n",
    "\n",
    "\n",
    "'''\n",
    "Transforms alphabetical input to numerical input, replace each letter by its corresponding \n",
    "index from letter_list\n",
    "'''\n",
    "\n",
    "def transform_letter_to_index(transcript, letter_list):\n",
    "    '''\n",
    "    :param transcript :(N, ) Transcripts are the text input\n",
    "    :param letter_list: Letter list defined above\n",
    "    :return letter_to_index_list: Returns a list for all the transcript sentence to index\n",
    "    '''\n",
    "    letter_to_index_list = []\n",
    "    for transcript_train in transcript:\n",
    "        char_list = []\n",
    "        for i,word in enumerate(transcript_train):\n",
    "            if i == 0:\n",
    "                char_list.append(letter_list.index('<sos>'))\n",
    "\n",
    "            for char in word.decode('utf-8'):\n",
    "                char_list.append(letter_list.index(char))\n",
    "\n",
    "            if i == len(transcript_train)-1:\n",
    "                char_list.append(letter_list.index('<eos>'))\n",
    "            else:\n",
    "                char_list.append(letter_list.index(' '))\n",
    "        letter_to_index_list.append(char_list)\n",
    "    return letter_to_index_list\n",
    "\n",
    "\n",
    "'''\n",
    "Optional, create dictionaries for letter2index and index2letter transformations\n",
    "'''\n",
    "def create_dictionaries(letter_list):\n",
    "    letter2index = dict()\n",
    "    index2letter = dict()\n",
    "    return letter2index, index2letter\n",
    "\n",
    "\n",
    "class Speech2TextDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for the speech to text data, this may need some tweaking in the\n",
    "    getitem method as your implementation in the collate function may be different from\n",
    "    ours. \n",
    "    '''\n",
    "    def __init__(self, speech, text=None, isTrain=True):\n",
    "        self.speech = speech\n",
    "        self.isTrain = isTrain\n",
    "        if (text is not None):\n",
    "            self.text = text\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.speech.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if (self.isTrain == True):\n",
    "            return torch.tensor(self.speech[index].astype(np.float32)),torch.tensor(len(self.speech[index])), torch.tensor(self.text[index]),torch.tensor(len(self.text[index]))\n",
    "        else:\n",
    "            return torch.tensor(self.speech[index].astype(np.float32)),torch.tensor(len(self.speech[index]))\n",
    "\n",
    "\n",
    "def collate_train(seq_list):\n",
    "    ### Return the padded speech and text data, and the length of utterance and transcript ###\n",
    "    X=[]\n",
    "    X_len = []\n",
    "    Y=[]\n",
    "    Y_len = []\n",
    "    for i in range(len(seq_list)):\n",
    "        X.append(seq_list[i][0])\n",
    "        X_len.append(seq_list[i][1])\n",
    "        Y.append(seq_list[i][2])\n",
    "        Y_len.append(seq_list[i][3])\n",
    "        \n",
    "    inputs = torch.nn.utils.rnn.pad_sequence(X,padding_value=0.0)\n",
    "    targets = torch.nn.utils.rnn.pad_sequence(Y,batch_first=True,padding_value=0.0)\n",
    "    return inputs,torch.tensor(X_len),targets,torch.tensor(Y_len)\n",
    "\n",
    "\n",
    "def collate_test(seq_list):\n",
    "    ### Return padded speech and length of utterance ###\n",
    "    X=[]\n",
    "    X_len = []\n",
    "    for i in range(len(seq_list)):\n",
    "        X.append(seq_list[i][0])\n",
    "        X_len.append(seq_list[i][1])\n",
    "        \n",
    "    inputs = torch.nn.utils.rnn.pad_sequence(X,padding_value=0.0)\n",
    "    return inputs,torch.tensor(X_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_train, speech_valid, speech_test, transcript_train, transcript_valid = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_attn_flow(attn_mask, path):\n",
    "    plt.imsave(path, attn_mask, cmap='hot')\n",
    "    return plt\n",
    "\n",
    "def plot_grad_flow(named_parameters, path):\n",
    "    ave_grads = []\n",
    "    max_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            if(p is not None):\n",
    "                layers.append(n)\n",
    "                ave_grads.append(p.grad.abs().mean())\n",
    "                max_grads.append(p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    #plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "    plt.show()\n",
    "    plt.savefig(path)\n",
    "    return plt, max_grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as utils\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    '''\n",
    "    Attention is calculated using key, value and query from Encoder and decoder.\n",
    "    Below are the set of operations you need to perform for computing attention:\n",
    "        energy = bmm(key, query)\n",
    "        attention = softmax(energy)\n",
    "        context = bmm(attention, value)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def forward(self, query, key, value, lens):\n",
    "        '''query, context, lengths):\n",
    "        :param query :(batch_size, hidden_size) Query is the output of LSTMCell from Decoder\n",
    "        :param keys: (batch_size, max_len, encoder_size) Key Projection from Encoder\n",
    "        :param values: (batch_size, max_len, encoder_size) Value Projection from Encoder\n",
    "        :return context: (batch_size, encoder_size) Attended Context\n",
    "        :return attention_mask: (batch_size, max_len) Attention mask that can be plotted \n",
    "        '''\n",
    "                \n",
    "        key = key.permute(1,0,2)\n",
    "        value = value.permute(1,0,2)\n",
    "\n",
    "        attention = torch.bmm(key, query.unsqueeze(2)).squeeze(2)\n",
    "        \n",
    "        mask = torch.arange(key.size(1)).unsqueeze(0) >= lens.unsqueeze(1)\n",
    "        \n",
    "        # Set attention logits at padding positions to negative infinity.\n",
    "        attention.masked_fill_(mask.cuda(), -1e9)\n",
    "        \n",
    "        # Take softmax over the \"source length\" dimension.\n",
    "        attention = nn.functional.softmax(attention, dim=1)\n",
    "        \n",
    "        out = torch.bmm(attention.unsqueeze(1), value).squeeze(1)\n",
    "        \n",
    "        # attention vectors are returned for visualization\n",
    "        return out, attention\n",
    "\n",
    "class pBLSTM(nn.Module):\n",
    "    '''\n",
    "    Pyramidal BiLSTM\n",
    "    The length of utterance (speech input) can be hundereds to thousands of frames long.\n",
    "    The Paper reports that a direct LSTM implementation as Encoder resulted in slow convergence,\n",
    "    and inferior results even after extensive training.\n",
    "    The major reason is inability of AttendAndSpell operation to extract relevant information\n",
    "    from a large number of input steps.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(pBLSTM, self).__init__()\n",
    "        self.blstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x :(N, T) input to the pBLSTM\n",
    "        :return output: (N, T, H) encoded sequence from pyramidal Bi-LSTM \n",
    "        '''\n",
    "        \n",
    "        x,lens = unpack(x)\n",
    "        x = x.permute(1,0,2)\n",
    "        if x.shape[1] % 2 != 0:\n",
    "            x = x[:,:-1,:]\n",
    "        x = x.reshape(x.shape[0],int(x.shape[1]/2),x.shape[2]*2)\n",
    "        x = x.permute(1,0,2)\n",
    "        x = pack(x,lengths=lens/2,enforce_sorted=False)\n",
    "        x,_ = self.blstm(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    Encoder takes the utterances as inputs and returns the key and value.\n",
    "    Key and value are nothing but simple projections of the output from pBLSTM network.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, value_size=128,key_size=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True)\n",
    "        \n",
    "        ### Add code to define the blocks of pBLSTMs! ###\n",
    "        self.pblstm1 = pBLSTM(hidden_dim*4,hidden_dim)\n",
    "        self.pblstm2 = pBLSTM(hidden_dim*4,hidden_dim)\n",
    "        self.pblstm3 = pBLSTM(hidden_dim*4,hidden_dim)\n",
    "        self.pblstm4 = pBLSTM(hidden_dim*4,hidden_dim)\n",
    "        \n",
    "        self.key_network = nn.Linear(hidden_dim*2, value_size)\n",
    "        self.value_network = nn.Linear(hidden_dim*2, key_size)\n",
    "\n",
    "    def forward(self, x, lens):\n",
    "        rnn_inp = utils.rnn.pack_padded_sequence(x, lengths=lens, batch_first=False, enforce_sorted=False)\n",
    "        outputs, _ = self.lstm(rnn_inp)\n",
    "        outputs = self.pblstm1(outputs)\n",
    "        outputs = self.pblstm2(outputs)\n",
    "        outputs = self.pblstm3(outputs)\n",
    "        outputs = self.pblstm4(outputs)\n",
    "        ### Use the outputs and pass it through the pBLSTM blocks! ###\n",
    "        \n",
    "        linear_input, lengths = utils.rnn.pad_packed_sequence(outputs)\n",
    "        keys = self.key_network(linear_input)\n",
    "        value = self.value_network(linear_input)\n",
    "        return keys, value, lengths \n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    As mentioned in a previous recitation, each forward call of decoder deals with just one time step, \n",
    "    thus we use LSTMCell instead of LSLTM here.\n",
    "    The output from the second LSTMCell can be used as query here for attention module.\n",
    "    In place of value that we get from the attention, this can be replace by context we get from the attention.\n",
    "    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance.\n",
    "    '''\n",
    "    def __init__(self, vocab_size, hidden_dim, value_size=128, key_size=128, isAttended=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim, padding_idx=0)\n",
    "        self.lstm1 = nn.LSTMCell(input_size=hidden_dim + value_size, hidden_size=hidden_dim)\n",
    "        self.lstm2 = nn.LSTMCell(input_size=hidden_dim, hidden_size=key_size)\n",
    "\n",
    "        self.isAttended = isAttended\n",
    "        if (isAttended == True):\n",
    "            self.attention = Attention()\n",
    "\n",
    "        self.character_prob = nn.Linear(key_size + value_size, vocab_size)\n",
    "\n",
    "    def forward(self, key, values, text=None, isTrain=True,lens=None):\n",
    "        '''\n",
    "        :param key :(T, N, key_size) Output of the Encoder Key projection layer\n",
    "        :param values: (T, N, value_size) Output of the Encoder Value projection layer\n",
    "        :param text: (N, text_len) Batch input of text with text_length\n",
    "        :param isTrain: Train or eval mode\n",
    "        :return predictions: Returns the character perdiction probability \n",
    "        '''\n",
    "        batch_size = key.shape[1]\n",
    "\n",
    "        if (isTrain == True):\n",
    "            #print(text)\n",
    "            max_len =  text.shape[1]\n",
    "            embeddings = self.embedding(text)\n",
    "        else:\n",
    "            max_len = 250\n",
    "\n",
    "        predictions = []\n",
    "        hidden_states = [None, None]\n",
    "        prediction = torch.zeros(batch_size,1).to(DEVICE)#(torch.ones(batch_size, 1)*33).to(DEVICE)\n",
    "        context = values[0,:,:]\n",
    "        attention_list = []\n",
    "        for i in range(max_len):\n",
    "            # * Implement Gumble noise and teacher forcing techniques \n",
    "            # * When attention is True, replace values[i,:,:] with the context you get from attention.\n",
    "            # * If you haven't implemented attention yet, then you may want to check the index and break \n",
    "            #   out of the loop so you do not get index out of range errors. \n",
    "            \n",
    "            if (isTrain):\n",
    "                char_embed = embeddings[:,i,:]\n",
    "            else:\n",
    "                char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "            \n",
    "            inp = torch.cat([char_embed,context], dim=1)\n",
    "            \n",
    "            hidden_states[0] = self.lstm1(inp, hidden_states[0])\n",
    "\n",
    "            inp_2 = hidden_states[0][0]\n",
    "            hidden_states[1] = self.lstm2(inp_2, hidden_states[1])\n",
    "\n",
    "            ### Compute attention from the output of the second LSTM Cell ###\n",
    "            output = hidden_states[1][0]\n",
    "            \n",
    "            if self.isAttended==True:\n",
    "                context, attention = self.attention(output,key,values,lens)\n",
    "                attention_list.append(attention[0].detach().cpu().numpy())\n",
    "                prediction = self.character_prob(torch.cat([output, context], dim=1))\n",
    "                predictions.append(prediction.unsqueeze(1))\n",
    "            else:\n",
    "                prediction = self.character_prob(torch.cat([output, values[i,:,:]], dim=1))\n",
    "                predictions.append(prediction.unsqueeze(1))\n",
    "        if self.isAttended==True:\n",
    "            return torch.cat(predictions, dim=1),attention_list\n",
    "        else:\n",
    "            return torch.cat(predictions, dim=1),None\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    '''\n",
    "    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder.\n",
    "    This is simply a wrapper \"model\" for your encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, vocab_size, hidden_dim, value_size=128, key_size=128, isAttended=False):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim)\n",
    "        self.decoder = Decoder(vocab_size, hidden_dim,isAttended=True)\n",
    "\n",
    "    def forward(self, speech_input, speech_len, text_input=None, isTrain=True):\n",
    "        key, value,lengths = self.encoder(speech_input, speech_len)\n",
    "        if (isTrain == True):\n",
    "            predictions,attention = self.decoder(key, value, text_input,lens=lengths)\n",
    "        else:\n",
    "            predictions,attention = self.decoder(key, value, text=None, isTrain=False,lens=lengths)\n",
    "        return predictions,attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "### Add Your Other Necessary Imports Here! ###\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    loss_history = []\n",
    "    start = time.time()\n",
    "    all_attentions = []\n",
    "    for j, (X,X_lens,Y,Y_lens) in enumerate(train_loader):\n",
    "        X,Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "        X_lens,Y_lens= X_lens.to(DEVICE),Y_lens.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "\n",
    "        out,attention_list = model(X,X_lens,Y[:,:-1])\n",
    "        loss += criterion(out.reshape(out.shape[0]*out.shape[1],out.shape[-1]), Y[:,1:].reshape(Y[:,1:].shape[0]*Y[:,1:].shape[1]))\n",
    "        \n",
    "        if j % 15 == 0:\n",
    "            print(f'Batch {j} has loss: {loss.item()}')\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        del X\n",
    "        del X_lens\n",
    "        del Y\n",
    "        del Y_lens\n",
    "        del loss\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'Time: {(end-start)/60}')\n",
    "    return attention_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 has loss: 3.5653891563415527\n",
      "Batch 15 has loss: 2.84572696685791\n",
      "Batch 30 has loss: 2.6806483268737793\n",
      "Batch 45 has loss: 2.4591357707977295\n",
      "Batch 60 has loss: 2.274397611618042\n",
      "Batch 75 has loss: 2.166311740875244\n",
      "Batch 90 has loss: 2.0933098793029785\n",
      "Batch 105 has loss: 2.040273904800415\n",
      "Batch 120 has loss: 2.015489339828491\n",
      "Batch 135 has loss: 2.0003626346588135\n",
      "Batch 150 has loss: 1.9396114349365234\n",
      "Batch 165 has loss: 1.9316234588623047\n",
      "Batch 180 has loss: 1.9001574516296387\n",
      "Batch 195 has loss: 1.86001455783844\n",
      "Batch 210 has loss: 1.8456873893737793\n",
      "Batch 225 has loss: 1.830087661743164\n",
      "Batch 240 has loss: 1.8065807819366455\n",
      "Batch 255 has loss: 1.7985484600067139\n",
      "Batch 270 has loss: 1.7689565420150757\n",
      "Batch 285 has loss: 1.7374876737594604\n",
      "Batch 300 has loss: 1.7554261684417725\n",
      "Batch 315 has loss: 1.753662109375\n",
      "Batch 330 has loss: 1.726441740989685\n",
      "Batch 345 has loss: 1.7080533504486084\n",
      "Batch 360 has loss: 1.7228367328643799\n",
      "Batch 375 has loss: 1.7124234437942505\n",
      "Batch 390 has loss: 1.6845142841339111\n",
      "Batch 405 has loss: 1.6956579685211182\n",
      "Batch 420 has loss: 1.669479250907898\n",
      "Batch 435 has loss: 1.6543021202087402\n",
      "Time: 6.35754923025767\n",
      "EPOCH 0\n",
      "Batch 0 has loss: 1.6427314281463623\n",
      "Batch 15 has loss: 1.6586205959320068\n",
      "Batch 30 has loss: 1.6651721000671387\n",
      "Batch 45 has loss: 1.649412989616394\n",
      "Batch 60 has loss: 1.6381100416183472\n",
      "Batch 75 has loss: 1.6550663709640503\n",
      "Batch 90 has loss: 1.662484884262085\n",
      "Batch 105 has loss: 1.6487057209014893\n",
      "Batch 120 has loss: 1.633673071861267\n",
      "Batch 135 has loss: 1.6028647422790527\n",
      "Batch 150 has loss: 1.6064990758895874\n",
      "Batch 165 has loss: 1.6342142820358276\n",
      "Batch 180 has loss: 1.5945876836776733\n",
      "Batch 195 has loss: 1.5994750261306763\n",
      "Batch 210 has loss: 1.5795669555664062\n",
      "Batch 225 has loss: 1.6293299198150635\n",
      "Batch 240 has loss: 1.561189889907837\n",
      "Batch 255 has loss: 1.5979373455047607\n",
      "Batch 270 has loss: 1.5610953569412231\n",
      "Batch 285 has loss: 1.5581880807876587\n",
      "Batch 300 has loss: 1.5741546154022217\n",
      "Batch 315 has loss: 1.5424635410308838\n",
      "Batch 330 has loss: 1.5500108003616333\n",
      "Batch 345 has loss: 1.5655570030212402\n",
      "Batch 360 has loss: 1.5828335285186768\n",
      "Batch 375 has loss: 1.543819546699524\n",
      "Batch 390 has loss: 1.5617551803588867\n",
      "Batch 405 has loss: 1.549448847770691\n",
      "Batch 420 has loss: 1.5492186546325684\n",
      "Batch 435 has loss: 1.5163644552230835\n",
      "Time: 6.336970790227254\n",
      "EPOCH 1\n",
      "Batch 0 has loss: 1.5083439350128174\n",
      "Batch 15 has loss: 1.5352858304977417\n",
      "Batch 30 has loss: 1.541503667831421\n",
      "Batch 45 has loss: 1.5144078731536865\n",
      "Batch 60 has loss: 1.5319597721099854\n",
      "Batch 75 has loss: 1.5198068618774414\n",
      "Batch 90 has loss: 1.4948889017105103\n",
      "Batch 105 has loss: 1.510966420173645\n",
      "Batch 120 has loss: 1.474352240562439\n",
      "Batch 135 has loss: 1.4733585119247437\n",
      "Batch 150 has loss: 1.497222900390625\n",
      "Batch 165 has loss: 1.4915130138397217\n",
      "Batch 180 has loss: 1.5037399530410767\n",
      "Batch 195 has loss: 1.4760509729385376\n",
      "Batch 210 has loss: 1.5141512155532837\n",
      "Batch 225 has loss: 1.474130630493164\n",
      "Batch 240 has loss: 1.459701657295227\n",
      "Batch 255 has loss: 1.5039277076721191\n",
      "Batch 270 has loss: 1.4701159000396729\n",
      "Batch 285 has loss: 1.4689311981201172\n",
      "Batch 300 has loss: 1.4897205829620361\n",
      "Batch 315 has loss: 1.4531625509262085\n",
      "Batch 330 has loss: 1.4639827013015747\n",
      "Batch 345 has loss: 1.4822934865951538\n",
      "Batch 360 has loss: 1.4569544792175293\n",
      "Batch 375 has loss: 1.466293215751648\n",
      "Batch 390 has loss: 1.4759173393249512\n",
      "Batch 405 has loss: 1.4453848600387573\n",
      "Batch 420 has loss: 1.4644297361373901\n",
      "Batch 435 has loss: 1.4549713134765625\n",
      "Time: 6.341288546721141\n",
      "EPOCH 2\n",
      "Batch 0 has loss: 1.4378676414489746\n",
      "Batch 15 has loss: 1.4595361948013306\n",
      "Batch 30 has loss: 1.45999014377594\n",
      "Batch 45 has loss: 1.4448118209838867\n",
      "Batch 60 has loss: 1.450681447982788\n",
      "Batch 75 has loss: 1.4514923095703125\n",
      "Batch 90 has loss: 1.4380595684051514\n",
      "Batch 105 has loss: 1.4327590465545654\n",
      "Batch 120 has loss: 1.4558137655258179\n",
      "Batch 135 has loss: 1.4392714500427246\n",
      "Batch 150 has loss: 1.4096813201904297\n",
      "Batch 165 has loss: 1.4395968914031982\n",
      "Batch 180 has loss: 1.4443669319152832\n",
      "Batch 195 has loss: 1.4088006019592285\n",
      "Batch 210 has loss: 1.4516350030899048\n",
      "Batch 225 has loss: 1.4390760660171509\n",
      "Batch 240 has loss: 1.3963030576705933\n",
      "Batch 255 has loss: 1.4061121940612793\n",
      "Batch 270 has loss: 1.4665812253952026\n",
      "Batch 285 has loss: 1.4562255144119263\n",
      "Batch 300 has loss: 1.440111756324768\n",
      "Batch 315 has loss: 1.4345262050628662\n",
      "Batch 330 has loss: 1.4398831129074097\n",
      "Batch 345 has loss: 1.4120397567749023\n",
      "Batch 360 has loss: 1.4200671911239624\n",
      "Batch 375 has loss: 1.4463789463043213\n",
      "Batch 390 has loss: 1.3931329250335693\n",
      "Batch 405 has loss: 1.3970563411712646\n",
      "Batch 420 has loss: 1.4181292057037354\n",
      "Batch 435 has loss: 1.4233438968658447\n",
      "Time: 6.339747349421184\n",
      "EPOCH 3\n",
      "Batch 0 has loss: 1.4139968156814575\n",
      "Batch 15 has loss: 1.430080533027649\n",
      "Batch 30 has loss: 1.402132272720337\n",
      "Batch 45 has loss: 1.3832943439483643\n",
      "Batch 60 has loss: 1.3721874952316284\n",
      "Batch 75 has loss: 1.3980684280395508\n",
      "Batch 90 has loss: 1.4393514394760132\n",
      "Batch 105 has loss: 1.4134101867675781\n",
      "Batch 120 has loss: 1.4119771718978882\n",
      "Batch 135 has loss: 1.4304859638214111\n",
      "Batch 150 has loss: 1.4083713293075562\n",
      "Batch 165 has loss: 1.4184964895248413\n",
      "Batch 180 has loss: 1.4266945123672485\n",
      "Batch 195 has loss: 1.417932391166687\n",
      "Batch 210 has loss: 1.3909657001495361\n",
      "Batch 225 has loss: 1.3798867464065552\n",
      "Batch 240 has loss: 1.398881196975708\n",
      "Batch 255 has loss: 1.4400219917297363\n",
      "Batch 270 has loss: 1.443668246269226\n",
      "Batch 285 has loss: 1.3671375513076782\n",
      "Batch 300 has loss: 1.3933184146881104\n",
      "Batch 315 has loss: 1.396699070930481\n",
      "Batch 330 has loss: 1.3887079954147339\n",
      "Batch 345 has loss: 1.3793026208877563\n",
      "Batch 360 has loss: 1.3996357917785645\n",
      "Batch 375 has loss: 1.409209966659546\n",
      "Batch 390 has loss: 1.389847993850708\n",
      "Batch 405 has loss: 1.361954689025879\n",
      "Batch 420 has loss: 1.3974735736846924\n",
      "Batch 435 has loss: 1.3472411632537842\n",
      "Time: 6.292831865946452\n",
      "EPOCH 4\n",
      "Batch 0 has loss: 1.3737787008285522\n",
      "Batch 15 has loss: 1.3919312953948975\n",
      "Batch 30 has loss: 1.374100685119629\n",
      "Batch 45 has loss: 1.3899866342544556\n",
      "Batch 60 has loss: 1.3662145137786865\n",
      "Batch 75 has loss: 1.4023363590240479\n",
      "Batch 90 has loss: 1.404691219329834\n",
      "Batch 105 has loss: 1.362587332725525\n",
      "Batch 120 has loss: 1.3899855613708496\n",
      "Batch 135 has loss: 1.3695785999298096\n",
      "Batch 150 has loss: 1.3945364952087402\n",
      "Batch 165 has loss: 1.3669474124908447\n",
      "Batch 180 has loss: 1.364630937576294\n",
      "Batch 195 has loss: 1.3607802391052246\n",
      "Batch 210 has loss: 1.3487721681594849\n",
      "Batch 225 has loss: 1.3799797296524048\n",
      "Batch 240 has loss: 1.3834360837936401\n",
      "Batch 255 has loss: 1.4024534225463867\n",
      "Batch 270 has loss: 1.3456928730010986\n",
      "Batch 285 has loss: 1.3705706596374512\n",
      "Batch 300 has loss: 1.4034450054168701\n",
      "Batch 315 has loss: 1.3674639463424683\n",
      "Batch 330 has loss: 1.3663897514343262\n",
      "Batch 345 has loss: 1.3611421585083008\n",
      "Batch 360 has loss: 1.3768188953399658\n",
      "Batch 375 has loss: 1.3844817876815796\n",
      "Batch 390 has loss: 1.384660005569458\n",
      "Batch 405 has loss: 1.358717918395996\n",
      "Batch 420 has loss: 1.3569968938827515\n",
      "Batch 435 has loss: 1.3983558416366577\n",
      "Time: 6.297162624200185\n",
      "EPOCH 5\n",
      "Batch 0 has loss: 1.3625584840774536\n",
      "Batch 15 has loss: 1.3667908906936646\n",
      "Batch 30 has loss: 1.3358768224716187\n",
      "Batch 45 has loss: 1.337735891342163\n",
      "Batch 60 has loss: 1.3458577394485474\n",
      "Batch 75 has loss: 1.3461389541625977\n",
      "Batch 90 has loss: 1.3470170497894287\n",
      "Batch 105 has loss: 1.3388603925704956\n",
      "Batch 120 has loss: 1.3623769283294678\n",
      "Batch 135 has loss: 1.3512815237045288\n",
      "Batch 150 has loss: 1.3409303426742554\n",
      "Batch 165 has loss: 1.3428176641464233\n",
      "Batch 180 has loss: 1.3351688385009766\n",
      "Batch 195 has loss: 1.3425956964492798\n",
      "Batch 210 has loss: 1.345381498336792\n",
      "Batch 225 has loss: 1.3673635721206665\n",
      "Batch 240 has loss: 1.3456498384475708\n",
      "Batch 255 has loss: 1.3432753086090088\n",
      "Batch 270 has loss: 1.3186842203140259\n",
      "Batch 285 has loss: 1.3403469324111938\n",
      "Batch 300 has loss: 1.3540542125701904\n",
      "Batch 315 has loss: 1.3340449333190918\n",
      "Batch 330 has loss: 1.3408045768737793\n",
      "Batch 345 has loss: 1.3419212102890015\n",
      "Batch 360 has loss: 1.3575862646102905\n",
      "Batch 375 has loss: 1.3531663417816162\n",
      "Batch 390 has loss: 1.326493263244629\n",
      "Batch 405 has loss: 1.3225476741790771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 420 has loss: 1.327275276184082\n",
      "Batch 435 has loss: 1.2881848812103271\n",
      "Time: 6.282207385698954\n",
      "EPOCH 6\n",
      "Batch 0 has loss: 1.3423268795013428\n",
      "Batch 15 has loss: 1.3109989166259766\n",
      "Batch 30 has loss: 1.3062008619308472\n",
      "Batch 45 has loss: 1.3411693572998047\n",
      "Batch 60 has loss: 1.3247040510177612\n",
      "Batch 75 has loss: 1.3381891250610352\n",
      "Batch 90 has loss: 1.3324694633483887\n",
      "Batch 105 has loss: 1.330281138420105\n",
      "Batch 120 has loss: 1.3548778295516968\n",
      "Batch 135 has loss: 1.3468801975250244\n",
      "Batch 150 has loss: 1.3455208539962769\n",
      "Batch 165 has loss: 1.3536370992660522\n",
      "Batch 180 has loss: 1.3098607063293457\n",
      "Batch 195 has loss: 1.313861608505249\n",
      "Batch 210 has loss: 1.3218474388122559\n",
      "Batch 225 has loss: 1.3366203308105469\n",
      "Batch 240 has loss: 1.3015645742416382\n",
      "Batch 255 has loss: 1.3520522117614746\n",
      "Batch 270 has loss: 1.331685185432434\n",
      "Batch 285 has loss: 1.3114471435546875\n",
      "Batch 300 has loss: 1.342331886291504\n",
      "Batch 315 has loss: 1.3250279426574707\n",
      "Batch 330 has loss: 1.3207647800445557\n",
      "Batch 345 has loss: 1.371767520904541\n",
      "Batch 360 has loss: 1.2987357378005981\n",
      "Batch 375 has loss: 1.2975518703460693\n",
      "Batch 390 has loss: 1.3341549634933472\n",
      "Batch 405 has loss: 1.3344470262527466\n",
      "Batch 420 has loss: 1.3379745483398438\n",
      "Batch 435 has loss: 1.3251837491989136\n",
      "Time: 6.277485835552215\n",
      "EPOCH 7\n",
      "Batch 0 has loss: 1.3076584339141846\n",
      "Batch 15 has loss: 1.330369234085083\n",
      "Batch 30 has loss: 1.3214446306228638\n",
      "Batch 45 has loss: 1.2960864305496216\n",
      "Batch 60 has loss: 1.306865930557251\n",
      "Batch 75 has loss: 1.3595136404037476\n",
      "Batch 90 has loss: 1.3542014360427856\n",
      "Batch 105 has loss: 1.2850110530853271\n",
      "Batch 120 has loss: 1.333664059638977\n",
      "Batch 135 has loss: 1.339177131652832\n",
      "Batch 150 has loss: 1.3266633749008179\n",
      "Batch 165 has loss: 1.292201280593872\n",
      "Batch 180 has loss: 1.3044688701629639\n",
      "Batch 195 has loss: 1.2793346643447876\n",
      "Batch 210 has loss: 1.3129520416259766\n",
      "Batch 225 has loss: 1.3277007341384888\n",
      "Batch 240 has loss: 1.2966108322143555\n",
      "Batch 255 has loss: 1.3037244081497192\n",
      "Batch 270 has loss: 1.3260291814804077\n",
      "Batch 285 has loss: 1.3136690855026245\n",
      "Batch 300 has loss: 1.3097518682479858\n",
      "Batch 315 has loss: 1.2974644899368286\n",
      "Batch 330 has loss: 1.328908085823059\n",
      "Batch 345 has loss: 1.325258493423462\n",
      "Batch 360 has loss: 1.3306849002838135\n",
      "Batch 375 has loss: 1.3192734718322754\n",
      "Batch 390 has loss: 1.3313459157943726\n",
      "Batch 405 has loss: 1.3024674654006958\n",
      "Batch 420 has loss: 1.345279574394226\n",
      "Batch 435 has loss: 1.3106688261032104\n",
      "Time: 6.366328231493632\n",
      "EPOCH 8\n",
      "Batch 0 has loss: 1.2858232259750366\n",
      "Batch 15 has loss: 1.3263113498687744\n",
      "Batch 30 has loss: 1.3109408617019653\n",
      "Batch 45 has loss: 1.3400541543960571\n",
      "Batch 60 has loss: 1.3020192384719849\n",
      "Batch 75 has loss: 1.3315315246582031\n",
      "Batch 90 has loss: 1.3067708015441895\n",
      "Batch 105 has loss: 1.3305290937423706\n",
      "Batch 120 has loss: 1.3037607669830322\n",
      "Batch 135 has loss: 1.3166818618774414\n",
      "Batch 150 has loss: 1.2831599712371826\n",
      "Batch 165 has loss: 1.3145290613174438\n",
      "Batch 180 has loss: 1.2874919176101685\n",
      "Batch 195 has loss: 1.3294589519500732\n",
      "Batch 210 has loss: 1.2790846824645996\n",
      "Batch 225 has loss: 1.3319975137710571\n",
      "Batch 240 has loss: 1.3280518054962158\n",
      "Batch 255 has loss: 1.3092995882034302\n",
      "Batch 270 has loss: 1.3286594152450562\n",
      "Batch 285 has loss: 1.2930468320846558\n",
      "Batch 300 has loss: 1.3109102249145508\n",
      "Batch 315 has loss: 1.3066085577011108\n",
      "Batch 330 has loss: 1.3036816120147705\n",
      "Batch 345 has loss: 1.286704659461975\n",
      "Batch 360 has loss: 1.3023346662521362\n",
      "Batch 375 has loss: 1.3020265102386475\n",
      "Batch 390 has loss: 1.3059005737304688\n",
      "Batch 405 has loss: 1.2970203161239624\n",
      "Batch 420 has loss: 1.311672568321228\n",
      "Batch 435 has loss: 1.3242082595825195\n",
      "Time: 6.343941124280294\n",
      "EPOCH 9\n",
      "Batch 0 has loss: 1.2959134578704834\n",
      "Batch 15 has loss: 1.2801309823989868\n",
      "Batch 30 has loss: 1.3089085817337036\n",
      "Batch 45 has loss: 1.2767250537872314\n",
      "Batch 60 has loss: 1.2858892679214478\n",
      "Batch 75 has loss: 1.3077619075775146\n",
      "Batch 90 has loss: 1.2906248569488525\n",
      "Batch 105 has loss: 1.307428002357483\n",
      "Batch 120 has loss: 1.2993589639663696\n",
      "Batch 135 has loss: 1.271568775177002\n",
      "Batch 150 has loss: 1.3010807037353516\n",
      "Batch 165 has loss: 1.3363416194915771\n",
      "Batch 180 has loss: 1.308633804321289\n",
      "Batch 195 has loss: 1.2673062086105347\n",
      "Batch 210 has loss: 1.3172754049301147\n",
      "Batch 225 has loss: 1.2799336910247803\n",
      "Batch 240 has loss: 1.3102624416351318\n",
      "Batch 255 has loss: 1.2895052433013916\n",
      "Batch 270 has loss: 1.297640085220337\n",
      "Batch 285 has loss: 1.2864047288894653\n",
      "Batch 300 has loss: 1.2698860168457031\n",
      "Batch 315 has loss: 1.3036032915115356\n",
      "Batch 330 has loss: 1.2788313627243042\n",
      "Batch 345 has loss: 1.2704203128814697\n",
      "Batch 360 has loss: 1.325750708580017\n",
      "Batch 375 has loss: 1.28568696975708\n",
      "Batch 390 has loss: 1.2708311080932617\n",
      "Batch 405 has loss: 1.3062622547149658\n",
      "Batch 420 has loss: 1.2777103185653687\n",
      "Batch 435 has loss: 1.3039189577102661\n",
      "Time: 6.361256690820058\n",
      "EPOCH 10\n",
      "Batch 0 has loss: 1.2909977436065674\n",
      "Batch 15 has loss: 1.2670011520385742\n",
      "Batch 30 has loss: 1.2951408624649048\n",
      "Batch 45 has loss: 1.2730079889297485\n",
      "Batch 60 has loss: 1.2790414094924927\n",
      "Batch 75 has loss: 1.3078519105911255\n",
      "Batch 90 has loss: 1.2411657571792603\n",
      "Batch 105 has loss: 1.3069323301315308\n",
      "Batch 120 has loss: 1.2667444944381714\n",
      "Batch 135 has loss: 1.2836525440216064\n",
      "Batch 150 has loss: 1.282641887664795\n",
      "Batch 165 has loss: 1.267769694328308\n",
      "Batch 180 has loss: 1.2821825742721558\n",
      "Batch 195 has loss: 1.2764447927474976\n",
      "Batch 210 has loss: 1.2706269025802612\n",
      "Batch 225 has loss: 1.295290231704712\n",
      "Batch 240 has loss: 1.308341383934021\n",
      "Batch 255 has loss: 1.3051649332046509\n",
      "Batch 270 has loss: 1.2928260564804077\n",
      "Batch 285 has loss: 1.2814178466796875\n",
      "Batch 300 has loss: 1.291621446609497\n",
      "Batch 315 has loss: 1.2690765857696533\n",
      "Batch 330 has loss: 1.2633180618286133\n",
      "Batch 345 has loss: 1.2851909399032593\n",
      "Batch 360 has loss: 1.2845709323883057\n",
      "Batch 375 has loss: 1.293870449066162\n",
      "Batch 390 has loss: 1.2809741497039795\n",
      "Batch 405 has loss: 1.2899985313415527\n",
      "Batch 420 has loss: 1.2600164413452148\n",
      "Batch 435 has loss: 1.3073186874389648\n",
      "Time: 6.370276077588399\n",
      "EPOCH 11\n",
      "Batch 0 has loss: 1.2873953580856323\n",
      "Batch 15 has loss: 1.2527228593826294\n",
      "Batch 30 has loss: 1.2592265605926514\n",
      "Batch 45 has loss: 1.2774150371551514\n",
      "Batch 60 has loss: 1.2935223579406738\n",
      "Batch 75 has loss: 1.2694170475006104\n",
      "Batch 90 has loss: 1.2536296844482422\n",
      "Batch 105 has loss: 1.257409691810608\n",
      "Batch 120 has loss: 1.2962175607681274\n",
      "Batch 135 has loss: 1.3066896200180054\n",
      "Batch 150 has loss: 1.2873276472091675\n",
      "Batch 165 has loss: 1.2735413312911987\n",
      "Batch 180 has loss: 1.2791814804077148\n",
      "Batch 195 has loss: 1.2804991006851196\n",
      "Batch 210 has loss: 1.2735897302627563\n",
      "Batch 225 has loss: 1.2788794040679932\n",
      "Batch 240 has loss: 1.2743293046951294\n",
      "Batch 255 has loss: 1.2894967794418335\n",
      "Batch 270 has loss: 1.2662097215652466\n",
      "Batch 285 has loss: 1.26138174533844\n",
      "Batch 300 has loss: 1.2653825283050537\n",
      "Batch 315 has loss: 1.2712050676345825\n",
      "Batch 330 has loss: 1.2627865076065063\n",
      "Batch 345 has loss: 1.2720096111297607\n",
      "Batch 360 has loss: 1.283473253250122\n",
      "Batch 375 has loss: 1.2731900215148926\n",
      "Batch 390 has loss: 1.288412094116211\n",
      "Batch 405 has loss: 1.2620147466659546\n",
      "Batch 420 has loss: 1.2884290218353271\n",
      "Batch 435 has loss: 1.2428830862045288\n",
      "Time: 6.311126697063446\n",
      "EPOCH 12\n",
      "Batch 0 has loss: 1.2803902626037598\n",
      "Batch 15 has loss: 1.2816580533981323\n",
      "Batch 30 has loss: 1.2743842601776123\n",
      "Batch 45 has loss: 1.285732626914978\n",
      "Batch 60 has loss: 1.3006254434585571\n",
      "Batch 75 has loss: 1.24820077419281\n",
      "Batch 90 has loss: 1.2810311317443848\n",
      "Batch 105 has loss: 1.2686432600021362\n",
      "Batch 120 has loss: 1.281622290611267\n",
      "Batch 135 has loss: 1.2859971523284912\n",
      "Batch 150 has loss: 1.27239191532135\n",
      "Batch 165 has loss: 1.2489187717437744\n",
      "Batch 180 has loss: 1.247542142868042\n",
      "Batch 195 has loss: 1.2717294692993164\n",
      "Batch 210 has loss: 1.296233892440796\n",
      "Batch 225 has loss: 1.2776507139205933\n",
      "Batch 240 has loss: 1.2584699392318726\n",
      "Batch 255 has loss: 1.2811723947525024\n",
      "Batch 270 has loss: 1.280781865119934\n",
      "Batch 285 has loss: 1.2756096124649048\n",
      "Batch 300 has loss: 1.272573471069336\n",
      "Batch 315 has loss: 1.2762467861175537\n",
      "Batch 330 has loss: 1.2629603147506714\n",
      "Batch 345 has loss: 1.2749508619308472\n",
      "Batch 360 has loss: 1.2742341756820679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 375 has loss: 1.2562503814697266\n",
      "Batch 390 has loss: 1.2899831533432007\n",
      "Batch 405 has loss: 1.2629534006118774\n",
      "Batch 420 has loss: 1.277705192565918\n",
      "Batch 435 has loss: 1.2471891641616821\n",
      "Time: 6.285720956325531\n",
      "EPOCH 13\n",
      "Batch 0 has loss: 1.268730640411377\n",
      "Batch 15 has loss: 1.2647590637207031\n",
      "Batch 30 has loss: 1.2819359302520752\n",
      "Batch 45 has loss: 1.291440486907959\n",
      "Batch 60 has loss: 1.2652580738067627\n",
      "Batch 75 has loss: 1.2442091703414917\n",
      "Batch 90 has loss: 1.239975929260254\n",
      "Batch 105 has loss: 1.2456506490707397\n",
      "Batch 120 has loss: 1.264572262763977\n",
      "Batch 135 has loss: 1.2538275718688965\n",
      "Batch 150 has loss: 1.2668341398239136\n",
      "Batch 165 has loss: 1.285172462463379\n",
      "Batch 180 has loss: 1.2615360021591187\n",
      "Batch 195 has loss: 1.265581488609314\n",
      "Batch 210 has loss: 1.2676359415054321\n",
      "Batch 225 has loss: 1.275172233581543\n",
      "Batch 240 has loss: 1.2755517959594727\n",
      "Batch 255 has loss: 1.2781726121902466\n",
      "Batch 270 has loss: 1.2707631587982178\n",
      "Batch 285 has loss: 1.2889281511306763\n",
      "Batch 300 has loss: 1.2699706554412842\n",
      "Batch 315 has loss: 1.2716197967529297\n",
      "Batch 330 has loss: 1.2730128765106201\n",
      "Batch 345 has loss: 1.256965160369873\n",
      "Batch 360 has loss: 1.2714093923568726\n",
      "Batch 375 has loss: 1.267045259475708\n",
      "Batch 390 has loss: 1.2966939210891724\n",
      "Batch 405 has loss: 1.2902812957763672\n",
      "Batch 420 has loss: 1.2840611934661865\n",
      "Batch 435 has loss: 1.2696131467819214\n",
      "Time: 6.284432486693064\n",
      "EPOCH 14\n",
      "Batch 0 has loss: 1.3004907369613647\n",
      "Batch 15 has loss: 1.2621512413024902\n",
      "Batch 30 has loss: 1.2388142347335815\n",
      "Batch 45 has loss: 1.2324042320251465\n",
      "Batch 60 has loss: 1.2034298181533813\n",
      "Batch 75 has loss: 1.2434948682785034\n",
      "Batch 90 has loss: 1.2593868970870972\n",
      "Batch 105 has loss: 1.269298791885376\n",
      "Batch 120 has loss: 1.2464667558670044\n",
      "Batch 135 has loss: 1.2778520584106445\n",
      "Batch 150 has loss: 1.2576487064361572\n",
      "Batch 165 has loss: 1.26059889793396\n",
      "Batch 180 has loss: 1.266342282295227\n",
      "Batch 195 has loss: 1.2557475566864014\n",
      "Batch 210 has loss: 1.2571501731872559\n",
      "Batch 225 has loss: 1.2467873096466064\n",
      "Batch 240 has loss: 1.2726143598556519\n",
      "Batch 255 has loss: 1.266912579536438\n",
      "Batch 270 has loss: 1.2495982646942139\n",
      "Batch 285 has loss: 1.2595038414001465\n",
      "Batch 300 has loss: 1.2743831872940063\n",
      "Batch 315 has loss: 1.2683038711547852\n",
      "Batch 330 has loss: 1.242106318473816\n",
      "Batch 345 has loss: 1.2682852745056152\n",
      "Batch 360 has loss: 1.2488261461257935\n",
      "Batch 375 has loss: 1.261833667755127\n",
      "Batch 390 has loss: 1.251571774482727\n",
      "Batch 405 has loss: 1.2592874765396118\n",
      "Batch 420 has loss: 1.261160969734192\n",
      "Batch 435 has loss: 1.2893551588058472\n",
      "Time: 6.286651349067688\n",
      "EPOCH 15\n",
      "Batch 0 has loss: 1.2493749856948853\n",
      "Batch 15 has loss: 1.244077444076538\n",
      "Batch 30 has loss: 1.2417203187942505\n",
      "Batch 45 has loss: 1.2713608741760254\n",
      "Batch 60 has loss: 1.2549692392349243\n",
      "Batch 75 has loss: 1.2744221687316895\n",
      "Batch 90 has loss: 1.2544360160827637\n",
      "Batch 105 has loss: 1.2386837005615234\n",
      "Batch 120 has loss: 1.262506365776062\n",
      "Batch 135 has loss: 1.2589255571365356\n",
      "Batch 150 has loss: 1.2531555891036987\n",
      "Batch 165 has loss: 1.249860167503357\n",
      "Batch 180 has loss: 1.233185052871704\n",
      "Batch 195 has loss: 1.2654765844345093\n",
      "Batch 210 has loss: 1.2427024841308594\n",
      "Batch 225 has loss: 1.2360124588012695\n",
      "Batch 240 has loss: 1.23227858543396\n",
      "Batch 255 has loss: 1.2530879974365234\n",
      "Batch 270 has loss: 1.2581716775894165\n",
      "Batch 285 has loss: 1.2638152837753296\n",
      "Batch 300 has loss: 1.2788045406341553\n",
      "Batch 315 has loss: 1.2488619089126587\n",
      "Batch 330 has loss: 1.243274450302124\n",
      "Batch 345 has loss: 1.2250182628631592\n",
      "Batch 360 has loss: 1.2309858798980713\n",
      "Batch 375 has loss: 1.2707207202911377\n",
      "Batch 390 has loss: 1.2655736207962036\n",
      "Batch 405 has loss: 1.223249077796936\n",
      "Batch 420 has loss: 1.2730849981307983\n",
      "Batch 435 has loss: 1.2485601902008057\n",
      "Time: 6.304445974032084\n",
      "EPOCH 16\n",
      "Batch 0 has loss: 1.2444162368774414\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-be5403bff987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mattn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mplot_attn_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Epoch_{epoch}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# val()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-57a4e7556d3c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Batch {j} has loss: {loss.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "LETTER_LIST = ['<pad>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \\\n",
    "               'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-', \"'\", '.', '_', '+', ' ','<sos>','<eos>']\n",
    "\n",
    "\n",
    "model = Seq2Seq(input_dim=40, vocab_size=len(LETTER_LIST), hidden_dim=128)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean',ignore_index=0)\n",
    "nepochs = 25\n",
    "batch_size = 64 if DEVICE == 'cuda' else 1 \n",
    "character_text_train = transform_letter_to_index(transcript_train, LETTER_LIST)\n",
    "character_text_valid = transform_letter_to_index(transcript_valid, LETTER_LIST)\n",
    "\n",
    "train_dataset = Speech2TextDataset(speech_train, character_text_train)\n",
    "\n",
    "test_dataset = Speech2TextDataset(speech_test, None, False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_train)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_test)\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    attn_mask = train(model, train_loader, criterion, optimizer, epoch)\n",
    "    plot_attn_flow(attn_mask, f'Epoch_{epoch}.png')\n",
    "    test(model, test_loader, epoch)\n",
    "    print(f'EPOCH {epoch}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for a few more epochs to see if it starts \"Paying Attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 has loss: 1.2587796449661255\n",
      "Batch 15 has loss: 1.2202048301696777\n",
      "Batch 30 has loss: 1.2254769802093506\n",
      "Batch 45 has loss: 1.2266666889190674\n",
      "Batch 60 has loss: 1.243112564086914\n",
      "Batch 75 has loss: 1.2216757535934448\n",
      "Batch 90 has loss: 1.258890986442566\n",
      "Batch 105 has loss: 1.2073585987091064\n",
      "Batch 120 has loss: 1.246994972229004\n",
      "Batch 135 has loss: 1.245572566986084\n",
      "Batch 150 has loss: 1.2636767625808716\n",
      "Batch 165 has loss: 1.2405892610549927\n",
      "Batch 180 has loss: 1.220415472984314\n",
      "Batch 195 has loss: 1.2707115411758423\n",
      "Batch 210 has loss: 1.2565006017684937\n",
      "Batch 225 has loss: 1.2359211444854736\n",
      "Batch 240 has loss: 1.2797437906265259\n",
      "Batch 255 has loss: 1.2618598937988281\n",
      "Batch 270 has loss: 1.2338792085647583\n",
      "Batch 285 has loss: 1.2452365159988403\n",
      "Batch 300 has loss: 1.2694497108459473\n",
      "Batch 315 has loss: 1.238133430480957\n",
      "Batch 330 has loss: 1.2468219995498657\n",
      "Batch 345 has loss: 1.2857352495193481\n",
      "Batch 360 has loss: 1.259308934211731\n",
      "Batch 375 has loss: 1.2313255071640015\n",
      "Batch 390 has loss: 1.2366526126861572\n",
      "Batch 405 has loss: 1.2258358001708984\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-b136c7e79caf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mattn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplot_attn_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Epoch_{10+epoch}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# val()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-57a4e7556d3c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#n_tokens = Y_lens.sum() - Y_lens.size(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_lens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-95ae7f92dfd5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, speech_input, speech_len, text_input, isTrain)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeech_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misTrain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misTrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-95ae7f92dfd5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, key, values, text, isTrain, lens)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0minp_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;31m### Compute attention from the output of the second LSTM Cell ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    attn_mask = train(model, train_loader, criterion, optimizer, epoch)\n",
    "    plot_attn_flow(attn_mask, f'Epoch_{10+epoch}.png')\n",
    "    # val()\n",
    "    test(model, test_loader, epoch)\n",
    "    print(f'EPOCH {epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "Final = []\n",
    "for i, (X,X_len) in enumerate(test_loader):\n",
    "    X,X_len = X.to(DEVICE),X_len.to(DEVICE)\n",
    "    out,_ = model(X,X_len,isTrain=False)\n",
    "    _,out2 = torch.max(out,dim=2)\n",
    "    out2 = out2.detach().cpu().numpy()\n",
    "    for batch in out2:\n",
    "        out = []\n",
    "        for word in batch:\n",
    "            if word == 33: # 33 --> <sos>\n",
    "                None\n",
    "            elif word == 34: # 34 --> <eos>\n",
    "                break\n",
    "            else:\n",
    "                out.append(LETTER_LIST[word])\n",
    "        Final.append(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es and the street was a great deal of the street and the street was a great deal of the street and the street was a great deal of the street and the street was a great deal of the street and the street was a great deal of the street and the street wa'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 652k/652k [00:03<00:00, 206kB/s]\n",
      "Successfully submitted to 11-785-Fall-20-Homework 4 Part 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ID = [i for i in range(len(Final))]\n",
    "df_pred = pd.DataFrame(data={'Id':ID,'label':Final})\n",
    "df_pred.to_csv(f'Prediction2.csv',index=False)\n",
    "!kaggle competitions submit -c 11-785-fall-20-homework-4-part-2 -f Prediction2.csv -m \"Submission last\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "OZXkCkQAN4GN",
    "kyznzSkUQHz1",
    "LxrMiMpxHhFY"
   ],
   "machine_shape": "hm",
   "name": "HW3_P2_Transcript_Generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
